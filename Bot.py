#!/usr/bin/env python3
import asyncio
import logging
import aiohttp
from aiogram import Bot, Dispatcher, F, types
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.filters import Command
from urllib.parse import quote

# –¢–û–ö–ï–ù–´ –í –ö–û–î–ï
BOT_TOKEN = "7762578506:AAH5qTqK1C6wYkZ2QfI6aG6hK6zJ6oK6zJ6"  # –¢–í–û–ô –¢–û–ö–ï–ù
API_KEY = "sk_pKWqZWQ9cdXNCIFRSjNqnQaCwEN7NNVx"

# üñºÔ∏è 10 –ö–ê–†–¢–ò–ù–û–ö
IMAGE_MODELS = {
    "flux": "üî• FLUX", "turbo": "‚ö° TURBO", "zimage": "üìà ZIMAGE",
    "gptimage": "ü§ñ GPT", "gptimage-large": "‚≠ê GPT 4K",
    "seedance": "üé≠ SEEDANCE", "seedance-pro": "‚≠ê SEEDANCE PRO",
    "vo": "üé® VO", "seedance-veo": "üåà VEO", "openai": "ü§ñ OPENAI"
}

# ü§ñ 9 –ß–ê–¢
CHAT_MODELS = {
    "grok": "üöÄ Grok", "claude": "üéØ Claude", "claude-fast": "‚ö° Claude Fast",
    "openai-large": "üåü OpenAI", "mistral": "üåç Mistral",
    "perplexity-fast": "üåê Perplexity", "deepseek": "üßÆ Deepseek",
    "chickytutor": "üìö Tutor", "nova-fast": "‚ö° Nova"
}

MISTRAL_SYSTEM_PROMPT = """
–í—ã–±–∏—Ä–∞–π –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.

–ö–ê–†–¢–ò–ù–ö–ê: flux/turbo/seedance (–Ω–∞—Ä–∏—Å—É–π, –∫–∞—Ä—Ç–∏–Ω–∫–∞, –∞–Ω–∏–º–µ)
–ö–û–î: grok (–ø–æ—Å—á–∏—Ç–∞–π, python)
–õ–û–ì–ò–ö–ê: claude
–†–£–°–°–ö–ò–ô: mistral
–§–ê–ö–¢–´: perplexity-fast

–¢–û–õ–¨–ö–û –æ–¥–Ω–æ —Å–ª–æ–≤–æ: flux, grok, claude, turbo, seedance
"""

logging.basicConfig(level=logging.INFO)
bot = Bot(token=BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)

class States(StatesGroup):
    waiting_image = State()

user_settings = {}
current_prompts = {}  # –•—Ä–∞–Ω–∏–º –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è callback

async def ask_mistral_route(prompt: str, no_image=False):
    """Mistral Router"""
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "mistral",
        "messages": [{"role": "system", "content": MISTRAL_SYSTEM_PROMPT}, {"role": "user", "content": prompt}],
        "max_tokens": 20
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post("https://gen.pollinations.ai/v1/chat/completions", 
                                  headers=headers, json=data, timeout=10) as r:
                if r.status == 200:
                    result = await r.json()
                    model = result['choices'][0]['message']['content'].strip().lower()
                    all_models = {**IMAGE_MODELS, **CHAT_MODELS}
                    if model in all_models:
                        return model
    except:
        pass
    
    # Fallback
    if any(kw in prompt.lower() for kw in ['–Ω–∞—Ä–∏—Å—É–π', '–∫–∞—Ä—Ç–∏–Ω–∫–∞', '–∞–Ω–∏–º–µ', '—Ä–∏—Å—É–Ω–æ–∫']):
        return "flux"
    elif any(kw in prompt.lower() for kw in ['–ø–æ—Å—á–∏—Ç–∞–π', '–∫–æ–¥', 'python']):
        return "grok"
    return "claude"

async def generate_image(message: types.Message, model: str, prompt: str):
    """–û–¢–ü–†–ê–í–õ–Ø–ï–¢ –ö–ê–†–¢–ò–ù–ö–£ –ü–†–Ø–ú–û –í –ß–ê–¢"""
    encoded = quote(prompt)
    url = f"https://gen.pollinations.ai/image/{encoded}?model={model}&width=1024&height=1024&key={API_KEY}"
    
    await message.answer_chat_action("upload_photo")
    
    try:
        await message.answer_photo(
            photo=url,
            caption=f"üñºÔ∏è *{IMAGE_MODELS[model]}*\n`{prompt}`",
            parse_mode="Markdown"
        )
    except:
        # –ï—Å–ª–∏ –Ω–µ –≥—Ä—É–∑–∏—Ç—Å—è –∫–∞–∫ —Ñ–æ—Ç–æ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
        await message.answer_photo(
            photo=url,
            caption=f"üñºÔ∏è *{IMAGE_MODELS[model]}*\n`{prompt}`",
            parse_mode="Markdown"
        )

async def generate_text(message: types.Message, model: str, prompt: str):
    """–¢–µ–∫—Å—Ç"""
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    data = {"model": model, "messages": [{"role": "user", "content": prompt}], "max_tokens": 800}
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post("https://gen.pollinations.ai/v1/chat/completions", 
                                  headers=headers, json=data, timeout=30) as r:
                if r.status == 200:
                    result = await r.json()
                    text = result['choices'][0]['message']['content']
                    model_name = CHAT_MODELS.get(model, model.upper())
                    await message.answer(f"ü§ñ *{model_name}*\n\n{text}", parse_mode="Markdown")
                else:
                    await message.answer(f"‚ùå –û—à–∏–±–∫–∞ {model}")
    except:
        await message.answer("‚è∞ –¢–∞–π–º–∞—É—Ç, –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑")

@dp.message(Command("start"))
async def start(message: types.Message):
    kb = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton("üñºÔ∏è –¢–µ—Å—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏", callback_data="test_img")],
        [InlineKeyboardButton("ü§ñ –¢–µ—Å—Ç —Ç–µ–∫—Å—Ç–∞", callback_data="test_text")],
        [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", callback_data="settings")]
    ])
    await message.answer(
        "üöÄ *Pollinations AI Router v2026*\n\n"
        "üñºÔ∏è 10 –º–æ–¥–µ–ª–µ–π –∫–∞—Ä—Ç–∏–Ω–æ–∫\n"
        "ü§ñ 9 –º–æ–¥–µ–ª–µ–π —á–∞—Ç–∞\n\n"
        "*–ù–∞–ø–∏—à–∏ –ª—é–±–æ–π –ø—Ä–æ–º–ø—Ç ‚Äî –±–æ—Ç —Å–∞–º –≤—ã–±–µ—Ä–µ—Ç –º–æ–¥–µ–ª—å!*",
        reply_markup=kb, parse_mode="Markdown"
    )

@dp.message()
async def handle_message(message: types.Message, state: FSMContext):
    prompt = message.text
    user_id = message.from_user.id
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç
    current_prompts[user_id] = prompt
    
    model = await ask_mistral_route(prompt)
    
    if model in IMAGE_MODELS:
        kb = InlineKeyboardMarkup(inline_keyboard=[
            [InlineKeyboardButton("‚úÖ –ö–∞—Ä—Ç–∏–Ω–∫–∞", callback_data=f"img_yes_{model}")],
            [InlineKeyboardButton("‚ùå –¢–µ–∫—Å—Ç", callback_data="text_yes")],
            [InlineKeyboardButton("üé® –î—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å", callback_data="img_choose")]
        ])
        
        await message.answer(
            f"üé® *{IMAGE_MODELS[model]}*\n\n"
            f"–•–æ—Ç–∏—Ç–µ *–∫–∞—Ä—Ç–∏–Ω–∫—É*?\n\n"
            f"`{prompt}`",
            reply_markup=kb, parse_mode="Markdown"
        )
        await state.set_state(States.waiting_image)
    else:
        await generate_text(message, model, prompt)

@dp.callback_query(F.data.startswith("img_yes_"))
async def img_yes(callback: CallbackQuery, state: FSMContext):
    _, model = callback.data.split("_", 2)
    user_id = callback.from_user.id
    prompt = current_prompts.get(user_id, "–∫–æ—Ç")
    
    await callback.message.edit_text(f"üñºÔ∏è *{IMAGE_MODELS[model]}* –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç...")
    await generate_image(callback.message, model, prompt)
    await state.clear()

@dp.callback_query(F.data == "text_yes")
async def text_yes(callback: CallbackQuery, state: FSMContext):
    user_id = callback.from_user.id
    prompt = current_prompts.get(user_id, "")
    model = await ask_mistral_route(prompt, no_image=True)
    
    await callback.message.edit_text("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ç–µ–∫—Å—Ç...")
    await generate_text(callback.message, model, prompt)
    await state.clear()

@dp.callback_query(F.data == "img_choose")
async def img_choose(callback: CallbackQuery, state: FSMContext):
    user_id = callback.from_user.id
    prompt = current_prompts.get(user_id, "")
    
    kb = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(IMAGE_MODELS[k], callback_data=f"img_model_{k}") for k in list(IMAGE_MODELS)[:2]],
        [InlineKeyboardButton(IMAGE_MODELS[k], callback_data=f"img_model_{k}") for k in list(IMAGE_MODELS)[2:4]],
        [InlineKeyboardButton(IMAGE_MODELS[k], callback_data=f"img_model_{k}") for k in list(IMAGE_MODELS)[4:6]],
        [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data="back_main")]
    ])
    
    await callback.message.edit_text(
        f"üé® *–í–´–ë–ï–†–ò –ú–û–î–ï–õ–¨ –î–õ–Ø:* `{prompt}`",
        reply_markup=kb, parse_mode="Markdown"
    )

@dp.callback_query(F.data.startswith("img_model_"))
async def img_model_select(callback: CallbackQuery, state: FSMContext):
    model = callback.data.split("img_model_")[1]
    user_id = callback.from_user.id
    prompt = current_prompts.get(user_id, "–∫–æ—Ç")
    
    await callback.message.edit_text(f"üñºÔ∏è *{IMAGE_MODELS[model]}*...")
    await generate_image(callback.message, model, prompt)
    await state.clear()

@dp.callback_query(F.data == "test_img")
async def test_img(callback: CallbackQuery):
    await callback.message.edit_text("üñºÔ∏è –¢–µ—Å—Ç flux...")
    await generate_image(callback.message, "flux", "–∫–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ")

@dp.callback_query(F.data == "test_text")
async def test_text(callback: CallbackQuery):
    await callback.message.edit_text("ü§ñ –¢–µ—Å—Ç grok...")
    await generate_text(callback.message, "grok", "–ø–æ—Å—á–∏—Ç–∞–π –±—É–∫–≤—ã r –≤ strawberry")

async def main():
    print("üöÄ Pollinations AI Router Bot v2026 –∑–∞–ø—É—â–µ–Ω!")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
